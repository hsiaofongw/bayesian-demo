\documentclass{ctexart}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{float}
\usepackage{booktabs}
\usepackage{hyperref}

\newcommand{\pr}{\mathrm{Pr}}
\newtheorem{theorem}{定理}

\title{使用贝叶斯方法进行推断}
\begin{document}
    \maketitle

    \section{独立性和条件独立性}

    \subsection{独立性}

    对于事件$A$和事件$B$，我们说事件$A$和事件$B$是互相独立的，如果：
    \begin{equation}
        \pr(A \cap B) = \pr(A) \pr(B).
    \end{equation}
    \subsection{条件概率}
    当已知事件$A$发生时，事件$B$发生的概率，称为事件$B$关于事件$A$的条件概率，记做：
    \begin{equation}
        \pr(B|A).
    \end{equation}
    容易证明，对任意事件$A$、事件$B$，恒有：
    \begin{equation}
        \pr(A)\pr(B|A) = \pr(A \cap B)
    \end{equation}
    如此一来，我们得到了一种计算条件概率的方法：
    \begin{equation}
        \pr(B|A) = \frac{\pr(A \cap B)}{\pr(A)} = \frac{\pr(A|B)\pr(B)}{\pr(A)}
        \label{eq:condition-1}
    \end{equation}
    式中，我们要求$\pr(A) \neq 0$.

    事件的独立性可以用条件概率来表述，具体地，我们有
    \begin{theorem}
        设$A,B$是事件，则
        \begin{equation}
        \pr(A \cap B) = \pr(A)\pr(B) \iff \pr(A) = \pr(A|B).
        \end{equation}
    \end{theorem}
    \begin{proof}
        充分性．设给定$\pr(A) = \pr(A|B)$. 那么
        \begin{equation}
            \pr(A)\pr(B) = \pr(A|B)\pr(B) = \pr(A\cap B)
        \end{equation}
        从而充分性成立．

        必要性．设给定$\pr(A\cap B) = \pr(A) \pr(B)$. 那么，假设$\pr(B) \neq 0$，则
        \begin{equation}
            \frac{\pr(A \cap B)}{\pr(B)} = \frac{\pr(A)\pr(B)}{\pr(B)} = \pr(A)
        \end{equation}
        依式\ref{eq:condition-1}，我们得到
        \begin{equation}
            \pr(A|B) = \pr(A)
        \end{equation}
        从而必要性成立．
    \end{proof}

    \subsection{条件独立性}
    条件独立性是说，当某个事件发生时，另外两个（或多个）事件互相独立．具体地，设$A,B,C$是事件，则事件$A$,事件$B$关于事件$C$条件独立是指：
    \begin{equation}
        \pr(A \cap B | C) = \pr(A | C) \pr(B | C)
    \end{equation}
    例如：「在吸烟的人群中，男性患肺癌的风险和女性患肺癌的风险相当」就是一个条件独立性的陈述．对于一个受访者，用$A$表示受访者是男性，$\neg A$表示受访者是女性，用$B$表示受访者患肺癌，$\neg B$表示受访者不患肺癌，用$C$表示吸烟，则上述论断可写为：
    \begin{equation}
        \pr(A \cap B | C) = \pr(A | C) \pr(B | C)
    \end{equation}
    我们亦有条件独立性的等价表述：
    \begin{theorem}
        设$A,B,C$是事件，则
        \begin{equation}
            \pr(A \cap B | C) = \pr(A | C) \pr(B | C) \iff \pr(A | B \cap C) = \pr(A | C)
        \end{equation}
    \end{theorem}
    \begin{proof}
        充分性．设给定$\pr(A|B\cap C)=\pr(A|C)$．注意到
        \begin{equation}
            \pr(A | B \cap C) = \frac{\pr(A \cap B \cap C)}{\pr(B \cap C)} = \frac{\pr(A\cap B \cap C)}{\pr(B|C) \pr(C)}
        \end{equation}
        所以
        \begin{equation}
            \frac{\pr(A\cap B \cap C)}{\pr(B|C)\pr(C)} = \pr(A|C)
        \end{equation}
        所以
        \begin{equation}
            \frac{\pr(A \cap B \cap C)}{\pr(C)} = \pr(A|C) \pr(B|C)
        \end{equation}
        对上列等式左边应用式\ref{eq:condition-1}，得
        \begin{equation}
            \pr(A \cap B | C) = \pr(A|C)\pr(B|C)
        \end{equation}
        于是充分性得证．从上述证明过程倒推回去可得到必要性．
    \end{proof}

    \section{朴素贝叶斯分类器}

    设我们有表 \ref{tab:dataset-1} 所示的数据集：
    \begin{table}[H]
        \begin{center}
            \caption{数据集}
            \label{tab:dataset-1}
            \begin{tabular}{cccc}
                \toprule
                $\boldsymbol{x}_1$ & $\cdots$ & $\boldsymbol{x_m}$ & $\boldsymbol{y}$ \\
                \midrule
                $x_{1}^{(1)}$ & $\cdots$ & $x_{m}^{(1)}$ & $y_1$ \\
                $\vdots$ & {} & $\vdots$ & $\vdots$ \\
                $x_{1}^{(N)}$ & $\cdots$ & $x_{m}^{(N)}$ & $y_N$ \\
                \bottomrule
            \end{tabular}
        \end{center}
    \end{table}
    我们希望利用表 \ref{tab:dataset-1} 所提供的数据训练得到一个分类器，它能够对于一个新的输入$\boldsymbol{x}^\star$，判断（预测）出该输入所对应的标签$y^\star$.

    设标签变量$\boldsymbol{y}$的取值范围是在$\{ c_1, c_2, \cdots, c_k \}$，而变量$\boldsymbol{x}_1,\cdots,\boldsymbol{x}_m$的取值都是离散的，那么每当得到一组输入$\boldsymbol{x}^\star=(x_1^{\star},\cdots,x_m^\star)$，我们能够计算出后验概率：
    \begin{equation}
        \pr(c_j | \boldsymbol{x}^\star).
    \end{equation}
    $y_\star$则是选取自
    \begin{equation}
        y_\star = \underset{c \in \{c_1,\cdots,c_k\}}{\arg\max} \pr(c|\boldsymbol{x}^\star)
    \end{equation}
    所以说现在的重点，就是如何去计算$\pr(c|\boldsymbol{x}^\star)$.

    \subsection{条件独立性假设}
    首先我们继续上一节的计算过程，展开$\pr(c|\boldsymbol{x}^\star)$：
    \begin{align}
        \pr(c|\boldsymbol{x}^\star) &= \frac{\pr(c) \pr(\boldsymbol{x}^\star | c)}{\pr(\boldsymbol{x}^\star)} \\
        &\propto \pr(c) \pr(\boldsymbol{x}^\star | c) \\
        &= \pr(c)\pr(\bigcap_{j=1}^{m}x_{j}^\star|c)
    \end{align}
    在贝叶斯方法中，有这样一个条件独立性假设：
    \begin{equation}
        \pr(\bigcap_{j=1}^{m} x_{j}^\star|c) = \prod_{j=1}^m \pr(x_{j}^\star|c)
    \end{equation}
    于是就有
    \begin{equation}
        \pr(c|\boldsymbol{x}^\star) \propto \pr(c) \prod_{j=1}^{m} \pr(x_{j}^\star | c)
    \end{equation}
    于是就有
    \begin{equation}
        y^\star = \underset{c \in \{c_1,\cdots,c_k\}}{\arg\max} \pr(c) \prod_{j=1}^{m} \pr(x_{j}^\star | c).
    \end{equation}
    这就是贝叶斯分类器的基本工作原理．

    \subsection{拉普拉斯平滑}
    为了避免连乘操作中出现的某个$\pr(x_j^\star|c)$为$0$使得整个连乘式的结果为$0$，可以引入拉普拉斯平滑操作．具体地，当在计算$\pr(x_j^\star|c)$时，需要先找到数据集（也就是表 \ref{tab:dataset-1}）中，那些$\boldsymbol{y}$列取值为$c$的行，然后再在这些行里边，找出变量$\boldsymbol{x}_j$取值为$x_j^\star$的哪些行，并且统计这些行的行数，当统计出来的行数为$0$时，就将$0$替换为$1$，这就是拉普拉斯平滑操作．

    \section{在西瓜数据集上进行推断}
    我们从互联网上收集来了西瓜数据集（表 \ref{tab:watermelon-1}）：
    \begin{table}[H]
        \begin{center}
            \caption{西瓜数据集}
            \label{tab:watermelon-1}
            \begin{tabular}{rlllllll}
                \toprule
              id & color & root & knock & texture & navel & touch & quality \\
                \midrule
                1 & 青绿 & 蜷缩 & 浊响 & 清晰 & 凹陷 & 硬滑 & 是 \\
                2 & 乌黑 & 蜷缩 & 沉闷 & 清晰 & 凹陷 & 硬滑 & 是 \\
                3 & 乌黑 & 蜷缩 & 浊响 & 清晰 & 凹陷 & 硬滑 & 是 \\
                4 & 青绿 & 蜷缩 & 沉闷 & 清晰 & 凹陷 & 硬滑 & 是 \\
                5 & 浅白 & 蜷缩 & 浊响 & 清晰 & 凹陷 & 硬滑 & 是 \\
                6 & 青绿 & 稍蜷 & 浊响 & 清晰 & 稍凹 & 软粘 & 是 \\
                7 & 乌黑 & 稍蜷 & 浊响 & 稍糊 & 稍凹 & 软粘 & 是 \\
                8 & 乌黑 & 稍蜷 & 浊响 & 清晰 & 稍凹 & 硬滑 & 是 \\
                9 & 乌黑 & 稍蜷 & 沉闷 & 稍糊 & 稍凹 & 硬滑 & 否 \\
            10 & 青绿 & 硬挺 & 清脆 & 清晰 & 平坦 & 软粘 & 否 \\
            11 & 浅白 & 硬挺 & 清脆 & 模糊 & 平坦 & 硬滑 & 否 \\
            12 & 浅白 & 蜷缩 & 浊响 & 模糊 & 平坦 & 软粘 & 否 \\
            13 & 青绿 & 稍蜷 & 浊响 & 稍糊 & 凹陷 & 硬滑 & 否 \\
            14 & 浅白 & 稍蜷 & 沉闷 & 稍糊 & 凹陷 & 硬滑 & 否 \\
            15 & 乌黑 & 稍蜷 & 浊响 & 清晰 & 稍凹 & 软粘 & 否 \\
            16 & 浅白 & 蜷缩 & 浊响 & 模糊 & 平坦 & 硬滑 & 否 \\
            17 & 青绿 & 蜷缩 & 沉闷 & 稍糊 & 稍凹 & 硬滑 & 否 \\
                \bottomrule
              \end{tabular}
        \end{center}
    \end{table}

    id 那一列是每个西瓜的唯一编号，不用做变量，quality 那列则是目标变量（也就是标签），第2列到第7列都是自变量．有了这些数据，再加上我们刚刚学过的朴素贝叶斯方法，使我们能够实现一个模型，这个模型能够根据西瓜的外表（颜色、根蒂、敲声、纹理等）来预判一个西瓜是否是好瓜．
\end{document}